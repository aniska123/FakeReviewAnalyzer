{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nayak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nayak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nayak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\nayak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ensure necessary NLTK resources are downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Preprocessed_OSF_Review_ds.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Unnamed: 0' in df.columns:\n",
    "    df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure text_ is a string and handle NaN values\n",
    "df['text_'] = df['text_'].astype(str).fillna(\"\")\n",
    "\n",
    "# Add text length feature\n",
    "df['length'] = df['text_'].apply(len)\n",
    "\n",
    "# Add word count feature\n",
    "df['word_count'] = df['text_'].apply(lambda x: len(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved text processing function\n",
    "def enhanced_text_process(text):\n",
    "    # Convert to lowercase and tokenize\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove punctuation and stopwords but KEEP some crucial words for sentiment analysis\n",
    "    # Keep words like \"amazing\", \"great\", \"best\", \"worst\", etc.\n",
    "    sentiment_words = ['amazing', 'great', 'best', 'good', 'excellent', 'wonderful', 'bad', \n",
    "                       'worst', 'terrible', 'poor', 'love', 'hate', 'awesome', 'horrible']\n",
    "    \n",
    "    filtered_tokens = []\n",
    "    for word in tokens:\n",
    "        # Keep word if it's not punctuation and either not a stopword or a sentiment word\n",
    "        if (word not in string.punctuation and \n",
    "            (word not in stopwords.words('english') or word.lower() in sentiment_words)):\n",
    "            filtered_tokens.append(word)\n",
    "    \n",
    "    return filtered_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional features\n",
    "def add_features(df):\n",
    "    # Create features from text characteristics that might help detect fake reviews\n",
    "    df['exclamation_count'] = df['text_'].apply(lambda x: x.count('!'))\n",
    "    df['question_count'] = df['text_'].apply(lambda x: x.count('?'))\n",
    "    df['uppercase_ratio'] = df['text_'].apply(\n",
    "        lambda x: sum(1 for c in x if c.isupper()) / len(x) if len(x) > 0 else 0\n",
    "    )\n",
    "    # Calculate average word length as a feature\n",
    "    df['avg_word_length'] = df['text_'].apply(\n",
    "        lambda x: sum(len(word) for word in x.split()) / len(x.split()) if len(x.split()) > 0 else 0\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new features\n",
    "df = add_features(df)\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = df['text_']\n",
    "y = df['label']\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for SVC\n",
    "svc_params = {\n",
    "    'C': 10.0,               # Regularization parameter\n",
    "    'kernel': 'linear',      # Kernel type\n",
    "    'gamma': 'scale',        # Kernel coefficient\n",
    "    'probability': True      # Enable probability estimates\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved pipeline with custom text processing\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=enhanced_text_process, \n",
    "                           max_features=50000,    # Increase vocabulary size\n",
    "                           ngram_range=(1, 3))),  # Include bigrams and trigrams\n",
    "    ('tfidf', TfidfTransformer(use_idf=True,      # Use inverse document frequency\n",
    "                              smooth_idf=True)),  # Smooth IDF weights\n",
    "    ('classifier', SVC(**svc_params))             # Use optimized SVC\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nayak\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:544: UserWarning: The parameter 'ngram_range' will not be used since 'analyzer' is callable'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict if a review is fake or real   explanation \n",
    "def predict_review(review_text, pipeline=pipeline):\n",
    "    # Make prediction with probability\n",
    "    prediction = pipeline.predict([review_text])[0]\n",
    "    probabilities = pipeline.predict_proba([review_text])[0]\n",
    "    \n",
    "    # Get confidence score for the prediction\n",
    "    confidence = probabilities[0] if prediction == \"CG\" else probabilities[1]\n",
    "    \n",
    "    # Analyze the review characteristics\n",
    "    review_length = len(review_text)\n",
    "    word_count = len(review_text.split())\n",
    "    exclamation_count = review_text.count('!')\n",
    "    \n",
    "    # Logic for very short and generic reviews\n",
    "    is_short = word_count < 5\n",
    "    is_generic = any(word in review_text.lower() for word in ['amazing', 'great', 'good', 'excellent', 'best'])\n",
    "    \n",
    "    # Adjust prediction for very short, generic, enthusiastic reviews (likely real but suspicious)\n",
    "    if is_short and is_generic and exclamation_count > 0:\n",
    "        if confidence < 0.85:  # If confidence is not very high\n",
    "            prediction = \"OR\"  # Change to Original\n",
    "            confidence = 1 - confidence  # Adjust confidence\n",
    "    \n",
    "    # Provide rationale\n",
    "    rationale = []\n",
    "    if is_short:\n",
    "        rationale.append(\"Review is very short\")\n",
    "    if is_generic:\n",
    "        rationale.append(\"Contains generic positive terms\")\n",
    "    if exclamation_count > 0:\n",
    "        rationale.append(f\"Contains {exclamation_count} exclamation marks\")\n",
    "    \n",
    "    # Return results as a dictionary\n",
    "    return {\n",
    "        \"prediction\": prediction,\n",
    "        \"confidence\": round(float(confidence), 4),\n",
    "        \"review\": review_text,\n",
    "        \"characteristics\": {\n",
    "            \"length\": review_length,\n",
    "            \"word_count\": word_count,\n",
    "            \"exclamation_count\": exclamation_count,\n",
    "            \"is_short\": is_short,\n",
    "            \"is_generic\": is_generic\n",
    "        },\n",
    "        \"rationale\": rationale\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prediction': 'OR', 'confidence': 0.2784, 'review': 'This product is amazing!', 'characteristics': {'length': 24, 'word_count': 4, 'exclamation_count': 1, 'is_short': True, 'is_generic': True}, 'rationale': ['Review is very short', 'Contains generic positive terms', 'Contains 1 exclamation marks']}\n"
     ]
    }
   ],
   "source": [
    "# Test the model with the sample review\n",
    "sample_review = \"This product is amazing!\"\n",
    "result = predict_review(sample_review)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation:\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          CG       0.85      0.88      0.87      7121\n",
      "          OR       0.87      0.85      0.86      7031\n",
      "\n",
      "    accuracy                           0.86     14152\n",
      "   macro avg       0.86      0.86      0.86     14152\n",
      "weighted avg       0.86      0.86      0.86     14152\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6253  868]\n",
      " [1073 5958]]\n",
      "Accuracy Score: 0.8628462408140192\n",
      "Model Prediction Accuracy: 86.28%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))\n",
    "print('Model Prediction Accuracy:', f\"{np.round(accuracy_score(y_test, y_pred)*100, 2)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to explain predictions for multiple example reviews\n",
    "def test_multiple_reviews():\n",
    "    examples = [\n",
    "        \"This product is amazing!\",\n",
    "        \"I absolutely love this item, it changed my life and solved all my problems!\",\n",
    "        \"Good quality product, arrived on time. Works as described.\",\n",
    "        \"Terrible product. Broke after two uses. Would not recommend.\",\n",
    "        \"The delivery was fast, packaging was good. Haven't tried the product yet.\",\n",
    "        \"This is the best purchase I have ever made in my entire life!!!!!\"\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    for example in examples:\n",
    "        results.append(predict_review(example))\n",
    "    \n",
    "    # Display results in a readable format\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"\\nExample {i+1}: \\\"{examples[i]}\\\"\")\n",
    "        print(f\"Prediction: {result['prediction']} (Confidence: {result['confidence']})\")\n",
    "        print(f\"Characteristics: {', '.join(result['rationale'])}\")\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 1: \"This product is amazing!\"\n",
      "Prediction: OR (Confidence: 0.2784)\n",
      "Characteristics: Review is very short, Contains generic positive terms, Contains 1 exclamation marks\n",
      "\n",
      "Example 2: \"I absolutely love this item, it changed my life and solved all my problems!\"\n",
      "Prediction: OR (Confidence: 0.6795)\n",
      "Characteristics: Contains 1 exclamation marks\n",
      "\n",
      "Example 3: \"Good quality product, arrived on time. Works as described.\"\n",
      "Prediction: CG (Confidence: 0.7284)\n",
      "Characteristics: Contains generic positive terms\n",
      "\n",
      "Example 4: \"Terrible product. Broke after two uses. Would not recommend.\"\n",
      "Prediction: CG (Confidence: 0.5522)\n",
      "Characteristics: \n",
      "\n",
      "Example 5: \"The delivery was fast, packaging was good. Haven't tried the product yet.\"\n",
      "Prediction: OR (Confidence: 0.8681)\n",
      "Characteristics: Contains generic positive terms\n",
      "\n",
      "Example 6: \"This is the best purchase I have ever made in my entire life!!!!!\"\n",
      "Prediction: OR (Confidence: 0.8522)\n",
      "Characteristics: Contains generic positive terms, Contains 5 exclamation marks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prediction': 'OR',\n",
       "  'confidence': 0.2784,\n",
       "  'review': 'This product is amazing!',\n",
       "  'characteristics': {'length': 24,\n",
       "   'word_count': 4,\n",
       "   'exclamation_count': 1,\n",
       "   'is_short': True,\n",
       "   'is_generic': True},\n",
       "  'rationale': ['Review is very short',\n",
       "   'Contains generic positive terms',\n",
       "   'Contains 1 exclamation marks']},\n",
       " {'prediction': 'OR',\n",
       "  'confidence': 0.6795,\n",
       "  'review': 'I absolutely love this item, it changed my life and solved all my problems!',\n",
       "  'characteristics': {'length': 75,\n",
       "   'word_count': 14,\n",
       "   'exclamation_count': 1,\n",
       "   'is_short': False,\n",
       "   'is_generic': False},\n",
       "  'rationale': ['Contains 1 exclamation marks']},\n",
       " {'prediction': 'CG',\n",
       "  'confidence': 0.7284,\n",
       "  'review': 'Good quality product, arrived on time. Works as described.',\n",
       "  'characteristics': {'length': 58,\n",
       "   'word_count': 9,\n",
       "   'exclamation_count': 0,\n",
       "   'is_short': False,\n",
       "   'is_generic': True},\n",
       "  'rationale': ['Contains generic positive terms']},\n",
       " {'prediction': 'CG',\n",
       "  'confidence': 0.5522,\n",
       "  'review': 'Terrible product. Broke after two uses. Would not recommend.',\n",
       "  'characteristics': {'length': 60,\n",
       "   'word_count': 9,\n",
       "   'exclamation_count': 0,\n",
       "   'is_short': False,\n",
       "   'is_generic': False},\n",
       "  'rationale': []},\n",
       " {'prediction': 'OR',\n",
       "  'confidence': 0.8681,\n",
       "  'review': \"The delivery was fast, packaging was good. Haven't tried the product yet.\",\n",
       "  'characteristics': {'length': 73,\n",
       "   'word_count': 12,\n",
       "   'exclamation_count': 0,\n",
       "   'is_short': False,\n",
       "   'is_generic': True},\n",
       "  'rationale': ['Contains generic positive terms']},\n",
       " {'prediction': 'OR',\n",
       "  'confidence': 0.8522,\n",
       "  'review': 'This is the best purchase I have ever made in my entire life!!!!!',\n",
       "  'characteristics': {'length': 65,\n",
       "   'word_count': 13,\n",
       "   'exclamation_count': 5,\n",
       "   'is_short': False,\n",
       "   'is_generic': True},\n",
       "  'rationale': ['Contains generic positive terms',\n",
       "   'Contains 5 exclamation marks']}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run tests on multiple examples\n",
    "test_multiple_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to C:/Users/nayak/FakeReviewAnalyzer/backend/model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "import pickle\n",
    "model_path = \"C:/Users/nayak/FakeReviewAnalyzer/backend/model.pkl\"\n",
    "with open(model_path, \"wb\") as f:\n",
    "    pickle.dump(pipeline, f)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
